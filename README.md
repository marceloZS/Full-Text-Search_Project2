# Full-Text-Search_Project2
Proyecto 2 del curso de Base de datos 2. Construcci√≥n del √≠ndice invertido textual.

# Team - Group 5
| <a href="https://github.com/anamariaaccilio" target="_blank">**Ana Maria Accilio Villanueva**</a> | <a href="https://github.com/Diegospf12" target="_blank">**Diego Pacheco Ferrel**</a> | <a href="https://github.com/juanpedrovv" target="_blank">**Juan Pedro Vasquez Vilchez**</a> | <a href="https://github.com/LuisEnriqueCortijoGonzales" target="_blank">**Luis Enrique Cortijo Gonzales**</a> | <a href="https://github.com/marceloZS" target="_blank">**Marcelo Mario Zuloeta Salazar**</a> |
| :----------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------: |
| <img src="https://avatars.githubusercontent.com/u/91237434?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/94090499?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/83739305?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/84096868?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/85197213?v=4" alt="drawing" width="200"/> |

<a name="readme-top"></a>
<details open>
  <summary><h2>Tabla de contenidos:<h2></summary>
  <ul>
    <li><a href="#Introducci√≥n-üñä">Introducci√≥n
      <ul>
        <li><a href="#objetivo-del-proyecto">Objetivo del proyecto</a></li>
        <li><a href="#Dominio-de-datos">Dominio de datos</a></li>
      </ul>
    </a></li> 
    <li><a href="#Estructura-del-proyecto">Estructura del proyecto</a></li>
    <li><a href="#Frontend-(GUI)">Frontend (GUI)</a></li>
    <li><a href="#Backend-(SPIMI)">Backend (SPIMI)</a></li>
    <li><a href="#¬øC√≥mo-se-construye-el-√≠ndice-invertido-en-PostgreSQL?">¬øC√≥mo se construye el √≠ndice invertido en PostgreSQL?</a></li>
    <li><a href="#Experimentaci√≥n">Experimentaci√≥n</a></li>
    <li><a href="#conclusiones">Conclusiones</a></li>
    <li><a href="#referencias-bibliogr√°ficas">Referencias bibliogr√°ficas</a></li>
</details>

<hr>

# Introducci√≥n
El √≠ndice invertido es una estructura de datos utilizada en motores de b√∫squeda y sistemas de recuperaci√≥n de informaci√≥n. Consiste en un diccionario que mapea t√©rminos a una lista de documentos en los que aparecen esos t√©rminos. Esta estructura permite una b√∫squeda eficiente de documentos que contengan ciertos t√©rminos clave. 

## Objetivo del proyecto
El presente proyecto tiene como objetivo desarrollar esta estructura de datos de manera eficiente, con motivo de realizar b√∫squedas r√°pidas en un conjunto de documentos.

# Dominio de datos
La base de datos utilizada es la Fashion Product Images. Esta contiene alrededor de 44 mil productos etiquetados por ID, categor√≠a, g√©nero, color, a√±o, etc.

# Estructura del proyecto
El algoritmo SPIMI (Single-Pass In-Memory Indexing) es un m√©todo utilizado para construir un √≠ndice invertido durante el proceso de indexaci√≥n de grandes conjuntos de datos. A diferencia de algunos algoritmos de indexaci√≥n que requieren m√∫ltiples pasadas sobre los datos, SPIMI realiza la construcci√≥n del √≠ndice en una sola pasada a trav√©s de los datos.

![spimi1](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi1.jpg)

Se calcula una sola vez la longitud de cada documento, y se lee el documento de entrada uno a uno (por ejemplo, un documento de texto) y se tokeniza en t√©rminos individuales. Cada t√©rmino se procesa por separado.

![spimi2](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi2.jpeg)

# Frontend (GUI)

![[imagen del front]](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/imagen_front_principal.png)
![[capybara logo]](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/logo.png)

¬øC√≥mo se utiliza la GUI?
Dentro de la carpeta frontend se ejecuta el archivo main.py, este desplegara una ventana en la cual se puede crear un usuario o inciar sesion. Posteriormente en la ventana principal podras realizar la busqueda ingresando una busqueda textual y el numero que se desea. en la lista inferior apareceran los resultados y a su vez se mostrara el tiempo que tardo y el total de resultados que se retornan al realizar la consulta.
# Backend (SPIMI)
El archivo inverted_index.py contiene la implementaci√≥n del √≠ndice invertido utilizando el algoritmo SPIMI (Single-Pass In-Memory Indexing). El algoritmo SPIMI divide el proceso de indexaci√≥n en bloques m√°s peque√±os para manejar grandes vol√∫menes de datos de manera eficiente.

El c√≥digo incluye las siguientes funciones principales:

1. spimi_invert(): Esta funci√≥n realiza la indexaci√≥n de los documentos presentes en una carpeta de entrada. Utiliza el algoritmo SPIMI para generar el √≠ndice invertido.

2. binary_search_term_blocks(): Esta funci√≥n realiza una b√∫squeda binaria en los bloques del √≠ndice invertido para encontrar un t√©rmino espec√≠fico. Utiliza una implementaci√≥n eficiente de b√∫squeda binaria para mejorar el rendimiento de la b√∫squeda.

3. cosine_similarity(): Esta funci√≥n calcula la similitud de coseno entre una consulta y los documentos indexados. Utiliza el √≠ndice invertido y los pesos TF-IDF para calcular la similitud de coseno.

## 1. M√âTODO SPIMI INVERT()

```python

def spimi_invert(self):
        documents = os.listdir(self.input_folder)
        documents_count = len(documents)
        documents_counter = 0
        block_number = 0

        for docID in documents:
            if docID.endswith(".txt"):
                documents_counter += 1
                file_route = os.path.join(self.input_folder, docID)
                file_content = open(file_route, encoding="utf-8").read().lower()

```

Leemos uno a uno de nuestros documentos no pre-procesados

```python
                '''Pre-processing'''
                # Tokenizamos nuestro txt
                tokens = nltk.word_tokenize(file_content)
                #Filtramos para que no pertenezca a los stopwords o no sea un valor no alfanumerico (Stopwords / Valores raros)
                terms = [word for word in tokens if not word in TextPreprocessor.stopwords and re.match("^[a-zA-Z]+$", word)]
                #Hacemos Stemming en el idioma respectivo
                terms = [TextPreprocessor.stemmer.stem(w) for w in terms]
```
Una vez obtenemos el documento no procesado:
- Lo tokenizamos
- Filtramos las Stopwords
- Hacemos Stemming

```python
                for term in terms:

                    if (sys.getsizeof(term) + sys.getsizeof([docID]) + sys.getsizeof(self.dictionary) > self.block_size_limit):
                        temp_dict = self.sort_terms()
                        self.write_block_to_disk(temp_dict, block_number)
                        temp_dict = {}
                        block_number += 1

                    if term not in self.dictionary:
                        self.dictionary[term] = [docID]
                    else:
                        self.dictionary[term].append(docID)

                if sys.getsizeof(self.dictionary) > self.block_size_limit or (documents_counter == documents_count - 1):
                    temp_dict = self.sort_terms()
                    self.write_block_to_disk(temp_dict, block_number)
                    temp_dict = {}
                    block_number += 1
```

Una vez ya pre-procesado el documento, leemos uno a uno los t√©rminos de este, y los vamos agregando al diccionario de la siguiente forma:

```python
diccionario = {'baron':['doc1278.txt', 'doc1299.txt'],
        'zascuss':['doc1278.txt'],
        'abbi': ['doc1299.txt'],
        'abraim' : ['doc12081.txt']
}
```

Una vez este diccionario llegue al l√≠mite de RAM:

- Ordenaremos este diccionario en orden alfab√©tico (sort_terms(self))
- y agregaremos su term frequency de la siguiente forma (sort_terms(self) llama al m√©todo calculate_tftd(self, pl_with_duplicates)):

```python
diccionario_temporal = {    'aaron':[['doc11987.txt', 1]],
                            'abascuss':[['doc1278.txt', 1], ['doc1998.txt', 6]],
                            'abbi':[['doc1299.txt', 2]],
                            'abf':[['doc1156.txt', 3]],
                            'abraim':[['doc12081.txt', 1]]  }
```
- Finalmente, este diccionario modificado lo cargamos a memoria secundaria con el m√©todo write_block_to_disk(self, term_postings_list, block_number), generando as√≠ un bloque (indice invertido local).

**Una vez se hayan terminado de procesar todos los documentos, y con ello haber creado todos los bloques, mergearemos todos estos bloques para crear un indice invertido global repartido en los n bloques.**

```python
        print("BLOCKS creation complete!")
        self.merge_blocks()
```

```python
Insertar codigo de merge blocks


```
Explicar c√≥digo de merge blocks



# ¬øC√≥mo se construye el √≠ndice invertido en PostgreSQL?

A grandes rasgos, para la construcci√≥n del √≠ndice invertido en PostgreSQL se necesitan 3 tablas principales.
- Una tabla para almacenar los documentos
- Una tabla para almacenar los t√©rminos
- Una tabla de relaci√≥n entre t√©rminos y documentos

A partir de esto, se requere extraer los t√©rminos de los documentos y almacenarlos en una tabla de t√©rminos. Por ejemplo, se tiene lo siguiente:
```sql
INSERT INTO terms (term)
SELECT DISTINCT unnest(string_to_array(lower(content), ' ')) AS term
FROM documents;
```

La funci√≥n string_to_array se utiliza para dividir el contenido de los documentos en t√©rminos individuales, y la funci√≥n unnest se utiliza para convertir el resultado en filas individuales.

Lo siguiente es armar la relaci√≥n entre los documentos y t√©rminos. Esto se puede lograr utilizando consultas SQL que identifiquen los t√©rminos que aparecen en cada documento y los almacenen en la tabla de relaci√≥n. Por ejemplo:
```sql
INSERT INTO document_term (document_id, term)
SELECT d.id, t.term
FROM documents d
JOIN terms t ON lower(d.content) LIKE '%' || t.term || '%';
```
Una vez que se han extra√≠do los t√©rminos y se ha creado la tabla de relaci√≥n, se pueden crear √≠ndices en las columnas relevantes para mejorar el rendimiento de las consultas de b√∫squeda. Por lo general, se crean √≠ndices en las columnas de t√©rminos y en las columnas de identificadores de documentos para acelerar las b√∫squedas.

Con el √≠ndice invertido ya constru√≠do se pueden realizar consultas de b√∫squeda utilizando cl√°usulas SQL como WHERE y JOIN. Estas consultas aprovechan los √≠ndices para buscar r√°pidamente los documentos que contienen los t√©rminos de b√∫squeda especificados. Por tal motivo, las b√∫squedas de texto se vuelven m√°s eficientes, ya que se evita la necesidad de realizar exploraciones completas de los documentos.

# Experimentaci√≥n

|      | Implementaci√≥n | Postgress |
|------|----------------|-----------|
| 1000 |     15 ms      |   19 ms   |
| 2000 |     34 ms      |   33 ms   |
| 4000 |     65 ms      |   72 ms   |
| 8000 |    190 ms      |  180 ms   |
|16000 |    295 ms      |  300 ms   |
|32000 |    333 ms      |  359 ms   |
|64000 |    380 ms      |  360 ms   |

Implementaci√≥n de √çndice Invertido

Nuestra implementaci√≥n personalizada de √≠ndice invertido ha demostrado ser eficiente en la b√∫squeda de datos basada en texto. Hemos medido el rendimiento de nuestra implementaci√≥n en milisegundos para una variedad de tama√±os de datos de prueba, desde 1,000 hasta 64,000 registros. 

PostgreSQL con √çndice Invertido

Por otro lado, hemos utilizado PostgreSQL con sus propios √≠ndices invertidos para realizar b√∫squedas de texto similares a nuestras pruebas con datos de prueba de tama√±os comparables.

Conclusi√≥n

Los resultados de nuestra comparaci√≥n indican que PostgreSQL supera ligeramente a nuestra implementaci√≥n personalizada de √≠ndice invertido en t√©rminos de rendimiento en la mayor√≠a de los escenarios. Aunque nuestra implementaci√≥n es eficiente, PostgreSQL, con su optimizaci√≥n interna y capacidad para manejar grandes conjuntos de datos, muestra tiempos de b√∫squeda ligeramente m√°s bajos en las pruebas.
